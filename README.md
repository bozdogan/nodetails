_2021-04-10_

NoDetails: Essence of the text
===============================

<!-- Keywords -->
**Keywords:** NoDetails, text summarization, machine learning, neural networks, recurrent neural networks, long short-term memory.

<!-- Problem ne, çözüm önerimiz ne? -->

Reading some text, especially a long text such as a research paper, requires certain concentration and time. While reading that text or article, people spend time and effort to read, understand, and interpret the content. They lose too much time on their work because their attention span is not enough to cover the entire text. In a lot of scenarios people cannot decide if reading all of it is really worth or just want to know what it is about and do not want to waste time figuring it out. As a solution to this problem, we develop the NoDetails project. This is an application to help you get a summary of an article, shorten it to only contain the important parts, and give you _the essence of the text._ 


<!-- Projenin amacı ne? -->

The main purpose of this study is to develop an end-to-end method for creating concise summaries and clear headlines that can capture the attention of readers, and convey a significant amount of relevant information. Our method covers a _machine learning model which is a _Recurrent Neural Network (RNN)._

The RNN model is mainly based on _Long Short-Term Memory (LSTM)_ cells and their ability to understand data as a sequence. (Sequence data means that the order things appear is meaningful, it is two separate cases if some word comes before or after another word.) <!-- b: Bunu önceki cümleye yedirmeli ya da bu konuya başka bir bölümde değinmeliyiz. --> The principle of combining abstractive and extractive text summarization techniques guided the creation of our method: A summary containing the same sentences as the original text was produced using the extractive text summarization technique, and this summary was then processed using the abstractive text summarization technique to produce a summary with new sentences that differed from the original.

For all this process, the model trained and tested with a large-scale data set. As a consequence, a different technique was used from other similar applications in the literature.

<!-- Ne yaptık, ne yapacağız? -->

<!-- Alın biraz da algoritma açıklayalım. -->

<!-- İşte çıktılar. -->

<!-- Son düşünceler ve kapanış -->